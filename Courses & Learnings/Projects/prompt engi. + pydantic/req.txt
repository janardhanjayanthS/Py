Project Requirements: AI To-Do Assistant
1. Maintain an in-memory list of tasks
Each task must have:
id (int)
task (str)
done (bool)

2. Create Pydantic models
AddTaskInput(task: str)
MarkDoneInput(task_id: int)
ListTasksInput() (empty)

3. Define three tools
add_task â†’ adds a new task
list_tasks â†’ returns all tasks
mark_done â†’ marks a task as completed
Each tool must use its corresponding Pydantic model.

4. System prompt requirements
Assistant is a to-do manager
Must use tool calling when adding/listing/updating tasks
Must ask for clarification if user input is unclear
Must not invent tasks

5. LLM workflow
Send user message + system prompt + tool specs
LLM picks a tool and outputs arguments
Validate with Pydantic
Execute tool
Send tool result back to LLM
LLM generates final answer


full description:
ğŸ¯ Goal

You will build an app where a user can type:

â€œAdd a task to buy milkâ€
â€œShow my tasksâ€
â€œMark the third task as doneâ€

The LLM will:

Decide which tool to call

Generate the correct JSON arguments

Your Python function (tool) will run

You send the result back to the LLM

LLM replies naturally to the user

ğŸ“Œ Requirements (No code, only tasks)
1. In-Memory To-Do List

Use a simple Python list:

[
  {"id": 1, "task": "Buy milk", "done": False},
  {"id": 2, "task": "Study Python", "done": False}
]


No files.
No database.
Just one list inside the script.

2. Pydantic Models

Create Pydantic models for tool inputs:

a) AddTaskInput

task: str

b) ListTasksInput

no fields (empty)

c) MarkDoneInput

task_id: int

These schemas are used in tool calling.

3. Tools (Functions)

Create 3 tools:

1ï¸âƒ£ add_task

Input â†’ AddTaskInput
Action â†’ append a new task to the list

2ï¸âƒ£ list_tasks

Input â†’ ListTasksInput
Action â†’ return all tasks

3ï¸âƒ£ mark_done

Input â†’ MarkDoneInput
Action â†’ set done=True for the matching task

4. System Prompt Requirements

Your system prompt must say:

â€œYou are a to-do assistant.â€

â€œAlways use tool calls when user asks to add, list, or update tasks.â€

â€œReturn structured function arguments using JSON.â€

â€œIf the user request is unclear, ask a clarifying question.â€

â€œDo not invent tasks.â€

5. LLM Workflow Requirements
When the user sends a message:

You send user input + system prompt + tool schemas.

LLM decides if a tool is needed.

LLM outputs JSON tool call like:

{
  "tool": "add_task",
  "arguments": {
    "task": "Buy milk"
  }
}


You validate arguments with Pydantic.

You run the tool (function).

You send the tool result back to the LLM.

LLM returns a final answer:

â€œOkay! I added â€˜Buy milkâ€™ to your tasks.â€

6. Example Interactions That Must Work
âœ” Adding a task

User:

â€œAdd clean the room to my to-do listâ€

LLM â†’ Calls add_task

âœ” Listing tasks

User:

â€œWhat tasks do I have?â€

LLM â†’ Calls list_tasks

âœ” Marking a task as done

User:

â€œMark task 2 as completedâ€

LLM â†’ Calls mark_done

âœ” Asking clarifying questions

User:

â€œMark it as doneâ€

LLM â†’ Should ask:

â€œWhich task do you want to mark as done?â€

(This tests prompt engineering)

7. Optional Add-Ons (for practice)

Add due dates

Add priority

Add delete_task tool

Add clear_completed tool

Add reminders (LLM reasoning + follow-up questions)
